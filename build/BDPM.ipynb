{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca9e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading BDPM ...\n",
      "Le fichier CIS_bdpm.txt a bien été téléchargé.\n",
      "Le fichier CIS_COMPO_bdpm.txt a bien été téléchargé.\n",
      "\n",
      " Finished. bdpm-search.json is available.\n",
      "CIS_bdpm.txt a été supprimé.\n",
      "CIS_COMPO_bdpm.txt a été supprimé.\n"
     ]
    }
   ],
   "source": [
    "# Filter BDPM for Recomedicales by djibe\n",
    "# TODO: Axa, anti Xa > anti-Xa; U.I. > UI; S.C. > SC; remove spaces in numbers\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "# Download BDPM\n",
    "urls = [\n",
    "    'https://base-donnees-publique.medicaments.gouv.fr/telechargement.php?fichier=CIS_bdpm.txt',\n",
    "    'https://base-donnees-publique.medicaments.gouv.fr/telechargement.php?fichier=CIS_COMPO_bdpm.txt'\n",
    "]\n",
    "\n",
    "print(\"Downloading BDPM ...\")\n",
    "for url in urls:\n",
    "    # Get filename from URL\n",
    "    filename = url.split('=')[-1]\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Le fichier {filename} a bien été téléchargé.\")\n",
    "    else:\n",
    "        print(f\"Échec du téléchargement du fichier {filename}.\")\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "csv_path = os.path.join(current_dir, 'CIS_bdpm.txt')\n",
    "df = pd.read_csv(csv_path, sep='\\t', lineterminator='\\r', encoding='windows-1252')\n",
    "\n",
    "df.columns = ['cis', 'libelle', 'forme', 'voie', 'statut', 'procedure', 'commercialisation', 'date_amm', 'statut_bdm', 'autorisation', 'titulaire', 'surveillance']\n",
    "df['cis'] = df['cis'].apply(lambda x: x.lstrip('\\n') if isinstance(x, str) else x)\n",
    "\n",
    "csv2_path = os.path.join(current_dir, 'CIS_COMPO_bdpm.txt')\n",
    "df2 = pd.read_csv(csv2_path, sep='\\t', lineterminator='\\r', encoding='windows-1252')\n",
    "\n",
    "df2.columns = ['cis', 'designation', 'code', 'dci', 'dosage', 'ref', 'nature', 'liaison', 'other']\n",
    "df2['cis'] = df2['cis'].apply(lambda x: x.lstrip('\\n') if isinstance(x, str) else x)\n",
    "\n",
    "# Display the DataFrame\n",
    "# print(\"First rows\")\n",
    "# print(df.head())\n",
    "\n",
    "# Keep selected columns\n",
    "df = df.loc[:, ['cis', 'libelle', 'forme', 'voie', 'procedure', 'commercialisation']]\n",
    "\n",
    "# Apply filters\n",
    "df.loc[df['procedure'] != 'Procédure centralisée', 'procedure'] = None\n",
    "df.loc[df['procedure'] == 'Procédure centralisée', 'procedure'] = 'Yes'\n",
    "\n",
    "df['libelle'] = df['libelle'].str.replace(r'(?i)\\bPOUR CENT\\b', '%', regex=True)\n",
    "df['libelle'] = df[\"libelle\"].str.replace(r\"\\bL\\.?\\s*P\\.?\", \"LP\", regex=True)\n",
    "df['libelle'] = df['libelle'].str.replace(r' à libération prolongée', '', regex=False)\n",
    "df2['dci'] = df2['dci'].str.replace(r'(?i)\\bPOUR CENT\\b', '%', regex=True)\n",
    "\n",
    "unwanted_libelle_values = [\"BOIRON\", \"COMPLEXE N\", \"COMPOSE\", \"VOMICA\", \"2CH\", \"3CH\", \"4CH\", \"5CH\", \"6CH\", \"8CH\"]\n",
    "unwanted_voie_values = [\"épilésionelle\", \"hemodialyse\", \"intraveineuse\", \"intrathécale\", \"intravesicale\"]\n",
    "\n",
    "df_filtered = df[\n",
    "    (df['commercialisation'] == 'Commercialisée') &\n",
    "    (~df['voie'].str.contains('|'.join(unwanted_voie_values), case=False, na=False)) &\n",
    "    (~df['libelle'].str.contains('|'.join(unwanted_libelle_values), case=False, na=False))\n",
    "]\n",
    "\n",
    "# print('Filtered:')\n",
    "# print(df_filtered.head())\n",
    "\n",
    "# Filter duplicates\n",
    "unwanted_words = [' ACCORD', ' AGEPHA', ' AHCL', ' ALCON', ' ALMUS', ' ALPEX', ' AP-HP', ' ARROW', ' ARROW GENERIQUES', ' BAYER', ' BETAPHARM', ' BGR', ' BIOGARAN', ' BLUEFISH', \\\n",
    "  ' CCD', ' CHAUVIN', ' CHEMINEAU', ' CHIESI', ' CONSEIL', ' Conseil', ' CRINEX', ' CRISTERS', ' CRISTERS PHARMA', ' DIPHARMA', ' EG LABO', ' EG', ' EVANS', ' EVOLUGEN', ' FAURE', ' FRANCE', ' GEN.ORPH', ' GENERIQUES', ' GERDA', ' GIFRER', ' GILBERT', ' HCS', ' HEALTHCARE', ' HIKMA', ' IBSA', ' K.S', ' KRKA D.D.', ' KRKA', \\\n",
    "  ' LA COLINA', ' LABORATOIRES ALTER', ' ALTER', ' MYLAN', ' NEURAXPHARM', ' NOR', ' PANPHARMA', ' PFIZER', ' PHARMA', ' PIERRE FABRE', ' PROVEPHARM', ' QUIVER', ' REF', ' RENAUDIN', ' RICHARD', \\\n",
    "  ' SANDOZ', ' SANTE', ' SFDB', ' SUBSTIPHARM', ' SUN', ' TEVA', ' TILLOMED', ' UPSA', ' URGO', ' VIATRIS', ' VJ-PHARM', ' WAYMADE', ' WELEDA', ' ZENTIVA K.S.',' ZENTIVA', ' ZF', ' ZYDUS', \\\n",
    "  ' (rapport amoxicilline/acide clavulanique : 8/1)', ' (rapport amoxicilline/acide clavulanique: 8/1)', ' (Rapport Amoxicilline/Acide clavulanique : 8/1)', ' en flacon', \\\n",
    "  ' LAB', ' LABO']\n",
    "\n",
    "def normalize_libelle(libelle):\n",
    "    for word in unwanted_words:\n",
    "        libelle = libelle.replace(word, '')\n",
    "    return libelle.strip()\n",
    "\n",
    "# Apply normalization to create a new column for comparison\n",
    "df_filtered['normalized_libelle'] = df_filtered['libelle'].apply(normalize_libelle)\n",
    "\n",
    "# Drop duplicates based on the normalized 'libelle'\n",
    "df_unique = df_filtered.drop_duplicates(subset='normalized_libelle')\n",
    "\n",
    "# Update the original 'libelle' column to the normalized version\n",
    "df_unique['libelle'] = df_unique['normalized_libelle']\n",
    "\n",
    "# Drop the auxiliary column used for normalization\n",
    "df_unique = df_unique.drop(columns=['normalized_libelle'])\n",
    "\n",
    "# Merge CSVs\n",
    "df_unique['dci'] = None\n",
    "# print(\"Add blank column\")\n",
    "# print(df_unique.head())\n",
    "\n",
    "df2_prioritized = df2.sort_values(by=['cis', 'nature'], key=lambda col: col != 'FT').drop_duplicates(subset='cis')\n",
    "df_unique = df_unique.merge(df2_prioritized[['cis', 'dci']], on='cis', how='left')\n",
    "df_unique.rename(columns={'dci_y': 'dci'}, inplace=True)\n",
    "\n",
    "# print(\"New DF\")\n",
    "# print(df_unique.head())\n",
    "\n",
    "# Function to remove blank keys (columns with NaN values) from each row during JSON export\n",
    "def row_filter(row):\n",
    "    return row.dropna().to_dict()\n",
    "\n",
    "# Select only the 'cis' and 'libelle' columns and save to a JSON file\n",
    "df_to_save = df_unique[['cis', 'libelle', 'procedure', 'dci']]\n",
    "df_to_save.apply(row_filter, axis=1).to_json('../static/data/bdpm-search.json', orient='records', force_ascii=False)\n",
    "print('\\n Terminé. bdpm-search.json est dans le dossier /static/data/ .')\n",
    "\n",
    "# Cleanup\n",
    "\n",
    "files_to_remove = [\"CIS_bdpm.txt\", \"CIS_COMPO_bdpm.txt\"]\n",
    "for fichier in files_to_remove:\n",
    "    try:\n",
    "        os.remove(fichier)\n",
    "        print(f\"{fichier} a été supprimé.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Le fichier {fichier} n'a pas été trouvé.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la suppression de {fichier}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
